{
  "metadata": {
    "generated_at": "2025-08-22T09:36:57.430182",
    "comparison_type": "comprehensive_model_analysis",
    "models_compared": [
      "base_model",
      "base_bf16",
      "finetuned_bf16",
      "finetuned_q4km"
    ],
    "benchmark_types": [
      "inference",
      "memory_retrieval"
    ]
  },
  "executive_summary": {
    "key_findings": {
      "fastest_inference": "base_bf16",
      "best_memory_precision": "finetuned_q4km",
      "fine_tuning_improved_memory": true,
      "quantization_preserves_quality": true
    },
    "performance_summary": {
      "base_model": {
        "inference_throughput": "18.14 tok/s",
        "memory_precision": "0.476",
        "inference_latency": "6.98s"
      },
      "base_bf16": {
        "inference_throughput": "65.81 tok/s",
        "memory_precision": "0.476",
        "inference_latency": "1.99s",
        "vs_base_precision": "+0.0%"
      },
      "finetuned_bf16": {
        "inference_throughput": "6.50 tok/s",
        "memory_precision": "0.476",
        "inference_latency": "17.51s",
        "vs_base_precision": "+0.0%"
      },
      "finetuned_q4km": {
        "inference_throughput": "16.15 tok/s",
        "memory_precision": "0.486",
        "inference_latency": "7.36s",
        "vs_base_precision": "+2.0%"
      }
    }
  },
  "inference_analysis": {
    "timestamp": "2025-08-22T09:36:57.429769",
    "models": {
      "base_model": {
        "name": "Base Model (4-bit)",
        "model_path": "unsloth/llama-3.1-8b-bnb-4bit",
        "metrics": {
          "average_latency": 6.978217892646789,
          "median_latency": 7.026846170425415,
          "p95_latency": 7.223238468170166,
          "average_throughput": 18.141208984553074,
          "median_throughput": 18.215853442007354,
          "average_tokens_generated": 126.54,
          "total_prompts": 50,
          "success_rate": 1.0
        }
      },
      "base_bf16": {
        "name": "Base Model (bf16)",
        "model_path": "meta-llama/Llama-3.1-8B-Instruct",
        "metrics": {
          "average_latency": 1.9896422553062438,
          "median_latency": 1.918365716934204,
          "p95_latency": 1.9714581966400146,
          "average_throughput": 65.80641894608844,
          "median_throughput": 66.7400169538027,
          "average_tokens_generated": 128.0,
          "total_prompts": 100,
          "success_rate": 1.0
        }
      },
      "finetuned_bf16": {
        "name": "Fine-tuned BF16",
        "model_path": "/home/ubuntu/mem0-assignment/model_cache/finetuned_gguf/unsloth.BF16.gguf",
        "metrics": {
          "average_latency": 17.514206023216246,
          "median_latency": 20.395874500274658,
          "p95_latency": 21.844064474105835,
          "average_throughput": 6.49866902382394,
          "median_throughput": 6.605913481488512,
          "average_tokens_generated": 115.02,
          "total_prompts": 50,
          "success_rate": 1.0
        }
      },
      "finetuned_q4km": {
        "name": "Fine-tuned Q4_K_M",
        "model_path": "/home/ubuntu/mem0-assignment/model_cache/finetuned_gguf/unsloth.Q4_K_M.gguf",
        "metrics": {
          "average_latency": 7.364310693740845,
          "median_latency": 8.005381345748901,
          "p95_latency": 9.10502314567566,
          "average_throughput": 16.147895015529315,
          "median_throughput": 16.891484958121964,
          "average_tokens_generated": 121.48,
          "total_prompts": 50,
          "success_rate": 1.0
        }
      }
    },
    "relative_performance": {
      "base_bf16": {
        "latency_ratio": 0.2851218299449785,
        "throughput_ratio": 3.627454983960632,
        "latency_change_percent": -71.48781700550215,
        "throughput_change_percent": 262.74549839606317
      },
      "finetuned_bf16": {
        "latency_ratio": 2.5098393734124618,
        "throughput_ratio": 0.3582268981828854,
        "latency_change_percent": 150.9839373412462,
        "throughput_change_percent": -64.17731018171146
      },
      "finetuned_q4km": {
        "latency_ratio": 1.0553282810932139,
        "throughput_ratio": 0.8901223192610244,
        "latency_change_percent": 5.532828109321381,
        "throughput_change_percent": -10.987768073897566
      }
    },
    "statistical_analysis": {
      "latency": {
        "fastest_model": "base_bf16",
        "slowest_model": "finetuned_bf16",
        "speed_range": 15.524563767910003,
        "coefficient_of_variation": 0.6665462464913965
      },
      "throughput": {
        "highest_throughput": "base_bf16",
        "lowest_throughput": "finetuned_bf16",
        "throughput_range": 59.307749922264506,
        "coefficient_of_variation": 0.8643081993766161
      }
    }
  },
  "memory_analysis": {
    "timestamp": "2025-08-22T09:36:57.430108",
    "models": {
      "base_model": {
        "name": "Base Model (4-bit)",
        "model_path": "unsloth/llama-3.1-8b-bnb-4bit",
        "metrics": {
          "average_precision_at_5": 0.4761904761904764,
          "median_precision_at_5": 0.4,
          "average_retrieval_time": 0.27933238801502047,
          "median_retrieval_time": 0.25061821937561035,
          "perfect_precision_queries": 1,
          "zero_precision_queries": 2,
          "total_queries": 21,
          "success_rate": 1.0,
          "precision_p95": 0.8
        }
      },
      "base_bf16": {
        "name": "Base Model (bf16)",
        "model_path": "meta-llama/Llama-3.1-8B-Instruct",
        "metrics": {
          "average_precision_at_5": 0.4761904761904764,
          "median_precision_at_5": 0.4,
          "average_retrieval_time": 0.27192005657014395,
          "median_retrieval_time": 0.2311389446258545,
          "perfect_precision_queries": 1,
          "zero_precision_queries": 2,
          "total_queries": 21,
          "success_rate": 1.0,
          "precision_p95": 0.8
        }
      },
      "finetuned_bf16": {
        "name": "Fine-tuned BF16",
        "model_path": "/home/ubuntu/mem0-assignment/model_cache/finetuned_gguf/unsloth.BF16.gguf",
        "metrics": {
          "average_precision_at_5": 0.4761904761904764,
          "median_precision_at_5": 0.4,
          "average_retrieval_time": 0.288430134455363,
          "median_retrieval_time": 0.24853134155273438,
          "perfect_precision_queries": 1,
          "zero_precision_queries": 2,
          "total_queries": 21,
          "success_rate": 1.0,
          "precision_p95": 0.8
        }
      },
      "finetuned_q4km": {
        "name": "Fine-tuned Q4_K_M",
        "model_path": "/home/ubuntu/mem0-assignment/model_cache/finetuned_gguf/unsloth.Q4_K_M.gguf",
        "metrics": {
          "average_precision_at_5": 0.48571428571428593,
          "median_precision_at_5": 0.4,
          "average_retrieval_time": 0.22482521193368094,
          "median_retrieval_time": 0.2014026641845703,
          "perfect_precision_queries": 1,
          "zero_precision_queries": 2,
          "total_queries": 21,
          "success_rate": 1.0,
          "precision_p95": 0.8
        }
      }
    },
    "relative_performance": {
      "base_bf16": {
        "precision_improvement": 0.0,
        "precision_improvement_percent": 0.0,
        "retrieval_time_ratio": 0.973464117435326,
        "retrieval_time_change_percent": -2.6535882564673945,
        "perfect_queries_improvement": 0,
        "zero_queries_change": 0
      },
      "finetuned_bf16": {
        "precision_improvement": 0.0,
        "precision_improvement_percent": 0.0,
        "retrieval_time_ratio": 1.0325696082183398,
        "retrieval_time_change_percent": 3.2569608218339834,
        "perfect_queries_improvement": 0,
        "zero_queries_change": 0
      },
      "finetuned_q4km": {
        "precision_improvement": 0.009523809523809545,
        "precision_improvement_percent": 2.000000000000004,
        "retrieval_time_ratio": 0.8048662510327713,
        "retrieval_time_change_percent": -19.513374896722873,
        "perfect_queries_improvement": 0,
        "zero_queries_change": 0
      }
    },
    "statistical_analysis": {
      "precision": {
        "best_model": "finetuned_q4km",
        "worst_model": "base_model",
        "precision_range": 0.009523809523809545,
        "mean_precision": 0.4785714285714288,
        "std_precision": 0.004123930494211622
      },
      "retrieval_time": {
        "fastest_model": "finetuned_q4km",
        "slowest_model": "finetuned_bf16",
        "time_range": 0.06360492252168204
      }
    },
    "improvement_analysis": {
      "expected_vs_actual": {
        "expected_precision_threshold": 0.6,
        "base_precision": 0.4761904761904764,
        "base_bf16_precision": 0.4761904761904764,
        "bf16_precision": 0.4761904761904764,
        "q4km_precision": 0.48571428571428593,
        "base_bf16_meets_expectation": false,
        "bf16_meets_expectation": false,
        "q4km_meets_expectation": false
      },
      "overall_assessment": {
        "fine_tuning_effective": true,
        "best_fine_tuned_model": "q4km",
        "precision_improvement_achieved": true,
        "quantization_impact": 0.009523809523809545,
        "recommendation": "Q4_K_M recommended: Only model showing memory improvement"
      }
    }
  },
  "trade_off_analysis": {
    "speed_vs_memory_quality": {
      "bf16": {
        "inference_speed_rank": 3,
        "memory_quality_rank": 4,
        "trade_off_ratio": 0.07327507747275255
      },
      "base_bf16": {
        "inference_speed_rank": 1,
        "memory_quality_rank": 3,
        "trade_off_ratio": 0.00723623141658252
      },
      "q4km": {
        "inference_speed_rank": 3,
        "memory_quality_rank": 1,
        "trade_off_ratio": 0.0300791084687619
      },
      "base": {
        "inference_speed_rank": 2,
        "memory_quality_rank": 2,
        "trade_off_ratio": 0.026249103717174767
      }
    },
    "model_efficiency": {
      "most_efficient_overall": "base_bf16",
      "best_for_memory_tasks": "finetuned_q4km",
      "best_for_speed_tasks": "base_bf16"
    }
  },
  "recommendations": {
    "use_case_recommendations": {
      "production_deployment": {
        "recommended_model": "finetuned_q4km",
        "reason": "Best balance of memory performance and inference speed"
      },
      "memory_critical_applications": {
        "recommended_model": "finetuned_q4km",
        "reason": "Highest memory retrieval precision"
      },
      "speed_critical_applications": {
        "recommended_model": "base_bf16",
        "reason": "Fastest inference with acceptable memory performance"
      },
      "resource_constrained_environments": {
        "recommended_model": "finetuned_q4km",
        "reason": "Good performance with lower memory footprint"
      }
    },
    "fine_tuning_assessment": {
      "was_successful": true,
      "best_fine_tuned_variant": "q4km",
      "quantization_impact": "minimal",
      "next_steps": [
        "Deploy fine-tuned model to production",
        "Conduct A/B testing with real users",
        "Benchmark on domain-specific evaluation sets",
        "Monitor performance in production environment"
      ]
    }
  }
}